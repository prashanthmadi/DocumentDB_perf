{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef21ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DELTA_TABLE_PATH = \"abfss://datacare@onelake.dfs.fabric.microsoft.com/mobileapps.Lakehouse/Tables/att/mobile_applications_partitioned\"\n",
    "MONGODB_DATABASE = \"mobile_apps_0126\"\n",
    "MONGODB_COLLECTION = \"applications_unsharded_1m\"\n",
    "conn_str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ff822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "print(\"âœ… Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b51341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from Delta Lake\n",
    "delta_df = spark.read.format(\"delta\").load(DELTA_TABLE_PATH)\n",
    "record_count = delta_df.count()\n",
    "\n",
    "print(f\"âœ… Loaded {record_count:,} records\")\n",
    "delta_df.select(\"_id\", \"fields.state\", \"fields.deviceManufacturer\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-adjust batch size based on record count\n",
    "if record_count <= 20000000:\n",
    "    BATCH_SIZE = \"2000\"\n",
    "elif record_count <= 50000000:\n",
    "    BATCH_SIZE = \"5000\"\n",
    "elif record_count <= 100000000:\n",
    "    BATCH_SIZE = \"8000\"\n",
    "else:\n",
    "    BATCH_SIZE = \"10000\"\n",
    "\n",
    "print(f\"ðŸ“¦ Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dabc8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Azure DocumentDB\n",
    "if not conn_str:\n",
    "    raise ValueError(\"âŒ Connection string not set\")\n",
    "\n",
    "print(f\"ðŸš€ Inserting {record_count:,} records...\")\n",
    "\n",
    "delta_df.write.format(\"mongodb\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option('connection.uri', conn_str) \\\n",
    "    .option(\"database\", MONGODB_DATABASE) \\\n",
    "    .option(\"collection\", MONGODB_COLLECTION) \\\n",
    "    .option(\"convertJson\", \"true\") \\\n",
    "    .option(\"idFieldList\", \"_id,fields.state\") \\\n",
    "    .option(\"ignoreNullValues\", \"true\") \\\n",
    "    .option(\"maxBatchSize\", BATCH_SIZE) \\\n",
    "    .option(\"operationType\", \"update\") \\\n",
    "    .option(\"ordered\", \"true\") \\\n",
    "    .option(\"upsertDocument\", \"true\") \\\n",
    "    .save()\n",
    "\n",
    "print(f\"âœ… Inserted {record_count:,} records\")\n",
    "print(f\"ðŸ—„ï¸  Database: {MONGODB_DATABASE}.{MONGODB_COLLECTION}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
